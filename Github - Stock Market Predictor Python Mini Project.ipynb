{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To find out top 10 companies for trading, used the Stock screener from investing.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv(\"Strong Buy or Sell.csv\")\n",
    "str1 = \"Strong Buy\"\n",
    "buy = []\n",
    "for row in df.iterrows():\n",
    "    #print(row[1][0])\n",
    "    buy.append(row[1][0])\n",
    "    for i in range(1, 6):\n",
    "        if row[1][i] != str1:\n",
    "            buy.pop()\n",
    "            break\n",
    "buy = pd.Series(buy)\n",
    "buy1 = [\"SBIN\", \"EMBASSY-RR\", \"LTI\", \"ABBOTINDIA\", \"VBL\", \"CROMPTON\", \"IIFL\", \"AJANTPHARM\", \"AKZOINDIA\", \"JMFINANCIL\", \"RITES\", \"JCHAC\", \"SPANDANA\", \"MCX\", \"VTL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           SBI\n",
      "1                                Embassy Office\n",
      "2                      Larsen & Toubro Infotech\n",
      "3                                  Abbott India\n",
      "4                               Varun Beverages\n",
      "5     Crompton Greaves Consumer Electricals Ltd\n",
      "6                                   Iifl Wealth\n",
      "7                             Ajanta Pharma Ltd\n",
      "8                              Akzo Nobel India\n",
      "9                                  JM Financial\n",
      "10                                        RITES\n",
      "11                 Johnson Controls-Hitachi Air\n",
      "12           Spandana Sphoorty Financial Ltd BO\n",
      "13                     Multi Commodity Exchange\n",
      "14                            Vardhman Textiles\n",
      "dtype: object\n",
      "Enter the number for the company you want to invest in: 0\n",
      "SBIN SBI\n"
     ]
    }
   ],
   "source": [
    "print(buy)\n",
    "company1 = int(input(\"Enter the number for the company you want to invest in: \"))\n",
    "company = buy1[company1]\n",
    "company2 = buy[company1]\n",
    "print(company, company2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good or Not Scraping from screener.in\n",
    "## Screener.in gives the the ROE, ROCE, Market Cap, etc. values based on which we can decide whether the stock is good for investment and/or intraday "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "market_cap: ['241,411'] Current_Price: ['270.50'] weeks_High: ['373.80'] Book_value: ['262.75'] Stock_PE: ['19.83'] Dividend_Yield: ['0.00'] ROCE: ['4.66'] ROE: ['1.00'] Sales_Growth: ['4.71']\n",
      "\n",
      "Stock is Not Good for Investment but Ok for Intraday.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "\n",
    "\n",
    "\n",
    "def good_or_not(company2):\n",
    "    driver = webdriver.Chrome(r'chromedriver.exe')\n",
    "    url = 'https://www.screener.in/'\n",
    "    driver.get(url)\n",
    "    sleep(2)\n",
    "    search_field = driver.find_element_by_xpath('/html/body/nav/div/div/div[1]/div/div/input')\n",
    "    search_field.send_keys(company2)\n",
    "    sleep(2)\n",
    "    driver.find_element_by_xpath('/html/body/nav/div/div/div[1]/div/div/ul/li[1]').click()\n",
    "    sleep(5)\n",
    "    market_cap=[]\n",
    "    Current_Price=[]\n",
    "    weeks_High=[]\n",
    "    Book_value=[] \n",
    "    Stock_PE=[]\n",
    "    Dividend_Yield=[]\n",
    "    ROCE=[]\n",
    "    ROE=[]\n",
    "    Sales_Growth=[]\n",
    "    for i in range(1,2):     \n",
    "        a=driver.find_element_by_xpath('/html/body/main/div/section[1]/ul/li['+str(i)+']/b').text\n",
    "        market_cap.append(a)\n",
    "        a1=driver.find_element_by_xpath('/html/body/main/div/section[1]/ul/li['+str(i+1)+']/b').text\n",
    "        Current_Price.append(a1)\n",
    "        a2=driver.find_element_by_xpath('/html/body/main/div/section[1]/ul/li['+str(i+2)+']/b').text\n",
    "        weeks_High.append(a2)\n",
    "        a3=driver.find_element_by_xpath('/html/body/main/div/section[1]/ul/li['+str(i+3)+']/b').text\n",
    "        Book_value.append(a3)\n",
    "        a4=driver.find_element_by_xpath('/html/body/main/div/section[1]/ul/li['+str(i+4)+']/b').text\n",
    "        Stock_PE.append(a4)\n",
    "        a5=driver.find_element_by_xpath('/html/body/main/div/section[1]/ul/li['+str(i+5)+']/b').text\n",
    "        Dividend_Yield.append(a5)\n",
    "        a6=driver.find_element_by_xpath('/html/body/main/div/section[1]/ul/li['+str(i+6)+']/b').text\n",
    "        ROCE.append(a6)\n",
    "        a7=driver.find_element_by_xpath('/html/body/main/div/section[1]/ul/li['+str(i+7)+']/b').text\n",
    "        ROE.append(a7)\n",
    "        a8=driver.find_element_by_xpath('/html/body/main/div/section[1]/ul/li['+str(i+8)+']/b').text\n",
    "        Sales_Growth.append(a8)\n",
    "        \n",
    "        stck=float(Stock_PE[0])\n",
    "        roce=float(ROCE[0])\n",
    "        roe=float(ROE[0])\n",
    "        \n",
    "    print('market_cap:',market_cap,'Current_Price:',Current_Price,'weeks_High:',weeks_High,'Book_value:',Book_value,'Stock_PE:',Stock_PE,'Dividend_Yield:',Dividend_Yield,'ROCE:',ROCE,'ROE:',ROE,'Sales_Growth:',Sales_Growth)\n",
    "     \n",
    "    driver.quit()\n",
    "    \n",
    "    if ((7<=stck<=30) and (roe>roce) and (12<=roe<=20)):\n",
    "        print('\\nStock is Good For Investment and also good for Intraday.')\n",
    "    else:\n",
    "        print('\\nStock is Not Good for Investment but Ok for Intraday.')\n",
    "       \n",
    "    \n",
    "good_or_not(company2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping yahoo finance for open, close, high, low, volume, adj.close, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "\n",
    "\n",
    "\n",
    "def get_table_with_links(company):\n",
    "    driver = webdriver.Chrome(r'chromedriver.exe')\n",
    "    url = 'https://in.finance.yahoo.com/'\n",
    "    driver.get(url)\n",
    "    sleep(2)\n",
    "    search_field = driver.find_element_by_id('yfin-usr-qry')\n",
    "    search_field.send_keys(company + \".NS\" + '\\n');\n",
    "    sleep(5)\n",
    "    a = driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[5]/section/div/ul/li[5]/a\")\n",
    "    a.click()\n",
    "    sleep(2)\n",
    "    #print('sss')\n",
    "    #for scrolling\n",
    "    for i in range(70):\n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    date = []\n",
    "    for i in driver.find_elements_by_xpath('//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div/table/tbody/tr/td[1]'):\n",
    "        try:\n",
    "            if i.text == \"-\":\n",
    "                date.insert(0,np.nan)\n",
    "            else:\n",
    "                child = i.find_element_by_xpath('./child::span')\n",
    "                date.insert(0,child.text)\n",
    "        except:\n",
    "            date.insert(0,np.nan)\n",
    "    df['date'] = pd.Series(date)\n",
    "    counts = []\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    open = []\n",
    "    for i in driver.find_elements_by_xpath('//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div/table/tbody/tr/td[2]'):\n",
    "        count += 1\n",
    "        try:\n",
    "            if i.text == \"-\":\n",
    "                open.insert(0,np.nan)\n",
    "            else:\n",
    "                child = i.find_element_by_xpath('./child::span')\n",
    "                if child.text == \"Dividend\" or child.text == \"Stock split\":\n",
    "                    counts.insert(0,count)\n",
    "                open.insert(0,child.text)\n",
    "        except:\n",
    "            open.insert(0,np.nan)\n",
    "    df['open'] = pd.Series(open)\n",
    "    \n",
    "    count = 0\n",
    "    high = []\n",
    "    for i in driver.find_elements_by_xpath('//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div/table/tbody/tr/td[3]'):\n",
    "        count += 1\n",
    "        if count in counts:\n",
    "            high.insert(0,\"Dividend\")\n",
    "            count += 1\n",
    "        try:\n",
    "            if i.text == \"-\":\n",
    "                high.insert(0,np.nan)\n",
    "            else:\n",
    "                child = i.find_element_by_xpath('./child::span')\n",
    "                high.insert(0,child.text)\n",
    "        except:\n",
    "            high.insert(0,np.nan)\n",
    "    df['high'] = pd.Series(high)\n",
    "    \n",
    "    count = 0\n",
    "    low = []\n",
    "    for i in driver.find_elements_by_xpath('//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div/table/tbody/tr/td[4]'):\n",
    "        count += 1\n",
    "        if count in counts:\n",
    "            low.insert(0,\"Dividend\")\n",
    "            count += 1\n",
    "        try:\n",
    "            if i.text == \"-\":\n",
    "                low.insert(0,np.nan)\n",
    "            else:\n",
    "                child = i.find_element_by_xpath('./child::span')\n",
    "                low.insert(0,child.text)\n",
    "        except:\n",
    "            low.insert(0,np.nan)\n",
    "    df['low'] = pd.Series(low)\n",
    "    \n",
    "    count = 0\n",
    "    close = []\n",
    "    for i in driver.find_elements_by_xpath('//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div/table/tbody/tr/td[5]'):\n",
    "        count += 1\n",
    "        if count in counts:\n",
    "            close.insert(0,\"Dividend\")\n",
    "            count += 1\n",
    "        try:\n",
    "            if i.text == \"-\":\n",
    "                close.insert(0,np.nan)\n",
    "            else:\n",
    "                child = i.find_element_by_xpath('./child::span')\n",
    "                close.insert(0,child.text)\n",
    "        except:\n",
    "            open.insert(0,np.nan)\n",
    "    df['close'] = pd.Series(close)\n",
    "    \n",
    "    count = 0\n",
    "    volume = []\n",
    "    for i in driver.find_elements_by_xpath('//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div/table/tbody/tr/td[6]' ):\n",
    "        count += 1\n",
    "        if count in counts:\n",
    "            volume.insert(0,\"Dividend\")\n",
    "            count += 1\n",
    "        try:\n",
    "            if i.text == \"-\":\n",
    "                volume.insert(0,np.nan)\n",
    "            else:\n",
    "                child = i.find_element_by_xpath('./child::span')\n",
    "                volume.insert(0,child.text)\n",
    "        except:\n",
    "            volume.insert(0,np.nan)\n",
    "    df['Adj. Close'] = pd.Series(volume)\n",
    "    \n",
    "    count = 0\n",
    "    volume = []\n",
    "    for i in driver.find_elements_by_xpath('//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div/table/tbody/tr/td[7]' ):\n",
    "        count += 1\n",
    "        if count in counts:\n",
    "            volume.insert(0,\"Dividend\")\n",
    "            count += 1\n",
    "        try:\n",
    "            if i.text == \"-\":\n",
    "                volume.insert(0,np.nan)\n",
    "            else:\n",
    "                child = i.find_element_by_xpath('./child::span')\n",
    "                volume.insert(0,child.text)\n",
    "        except:\n",
    "            volume.insert(0,np.nan)\n",
    "    df['volume'] = pd.Series(volume)\n",
    "    \n",
    "    driver.quit()\n",
    "    csv_name = \"stock_table_\" + company + \".csv\" \n",
    "    df.to_csv(csv_name, na_rep=np.nan)\n",
    "    \n",
    "get_table_with_links(company)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\aditi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def convert_cell(cell):\n",
    "    if cell == \"Dividend\" or cell == \"Stock split\" or cell == \"nan\":\n",
    "        return np.nan\n",
    "    return cell\n",
    "\n",
    "csv_name = \"stock_table_\" + company + \".csv\" \n",
    "\n",
    "df = pd.read_csv(csv_name, parse_dates=['date'], converters={\"open\": convert_cell,\n",
    "                                                                     \"high\": convert_cell,\n",
    "                                                                     \"low\": convert_cell,\n",
    "                                                                     \"close\": convert_cell,\n",
    "                                                                     \"Adj. Close\": convert_cell,\n",
    "                                                                     \"volume\": convert_cell,\n",
    "                                                                     \"open_tomorrow\": convert_cell})\n",
    "\n",
    "df1 = df.drop([\"Unnamed: 0\"], axis = 1).drop([\"date\"], axis = 1)\n",
    "df2 = df1.dropna()\n",
    "for i in df2.columns:\n",
    "    if i == \"date\":\n",
    "        continue\n",
    "    df2[i] = df2[i].str.replace(',','').astype(float)\n",
    "    #print(type(df2[i][1]))\n",
    "\n",
    "# A variable for predicting 'n' days out into the future\n",
    "forecast_out = 1 #'n=30' days\n",
    "#Create another column (the target ) shifted 'n' units up\n",
    "df2['Prediction'] = df2[['open']].shift(-forecast_out)\n",
    "#print the new data set\n",
    "#print(df2.head(31))\n",
    "\n",
    "### Create the independent data set (X)  #######\n",
    "# Convert the dataframe to a numpy array\n",
    "X = np.array(df2.drop(['Prediction'],1))\n",
    "#print(X)\n",
    "#Remove the last '30' rows\n",
    "X = X[:-forecast_out]\n",
    "#print(X)\n",
    "\n",
    "### Create the dependent data set (y)  #####\n",
    "# Convert the dataframe to a numpy array \n",
    "y = np.array(df2['Prediction'])\n",
    "# Get all of the y values except the last '30' rows\n",
    "y = y[:-forecast_out]\n",
    "#print(y)\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create and train the Linear Regression  Model\n",
    "lr = LinearRegression()\n",
    "# Train the model\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr confidence:  0.9867186138658526\n",
      "Today's Open value = 290.9\n",
      "Predicted Open value = [284.22653697]\n",
      "Actual Open value = 268.0\n"
     ]
    }
   ],
   "source": [
    "# Testing Model: Score returns the coefficient of determination R^2 of the prediction. \n",
    "# The best possible score is 1.0\n",
    "lr_confidence = lr.score(x_test, y_test)\n",
    "print(\"lr confidence: \", lr_confidence)\n",
    "\n",
    "# Set x_forecast equal to the last 30 rows of the original data set from Adj. Close column\n",
    "x_forecast = np.array(df2.drop(['Prediction'],1))[-forecast_out-1:-forecast_out]\n",
    "#print(df2.drop(['Prediction'], 1).columns)\n",
    "print(\"Today's Open value =\", x_forecast[0][0])\n",
    "\n",
    "# Print linear regression model predictions for the next '30' days\n",
    "lr_prediction = lr.predict(x_forecast)\n",
    "print(\"Predicted Open value =\", lr_prediction)\n",
    "# Print support vector regressor model predictions for the next '30' days\n",
    "#svm_prediction = svr_rbf.predict(x_forecast)\n",
    "#print(svm_prediction)\n",
    "\n",
    "x_forecast_actual = np.array(df2.drop(['Prediction'],1))[-forecast_out:]\n",
    "print(\"Actual Open value =\", x_forecast_actual[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
